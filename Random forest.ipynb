{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDS561Group24ProjectCode_IV.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7oYhpgXBXxiL",
        "WhDX54kQf4HR",
        "pjJzd9wMaqAZ",
        "GgHvGmnDkAos",
        "7Cfrkw25wp7v",
        "C_HSyyNczREY",
        "-RKKMbdx3eKA",
        "zxYWm4HCBa96",
        "zUwcMYM91vIx",
        "_Qn1_LMe6RLd",
        "v_hUKMx7tY0j",
        "YbopS9HAtkSX",
        "IhDV5GHt2ANZ",
        "gBMo4fpbyoq_",
        "QwlNQA1Y2FVX",
        "1jotn3s-B_63",
        "Zbxx_52lF5Tw",
        "b3V9957uF9yZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IDS 561 Group 24 Project Code\n",
        "\n",
        "ML Model: Random Forest"
      ],
      "metadata": {
        "id": "QDAYiiU8XIw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spark Data Frame Transformations and Actions"
      ],
      "metadata": {
        "id": "LA4xLbIE3oxB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJjOObIkNqbg"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "DogyV3FAOE8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Untar the Spark installer\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "kQCqIKZUOHXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ8Ty_wvOMiI",
        "outputId": "94723c33-7dbc-45af-a035-232b04ec2807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  spark-3.0.0-bin-hadoop3.2\tspark-3.0.0-bin-hadoop3.2.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "ehgniSjVOOsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "JTYK9yRiPBhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "0hsNPWoTQWCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z15xnfgxPEvk",
        "outputId": "bfa5f2ed-574d-42d7-b307-f831a2edfabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the directory to the required path\n",
        "%cd /content/drive/My Drive/Big Data Project\n",
        "!ls "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3oOl4DvQd7F",
        "outputId": "db8c9562-b7ca-4023-8abc-ab11117c2846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Big Data Project\n",
            "Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Creating the Environment"
      ],
      "metadata": {
        "id": "-VEKThVG_JKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For SQL-type queries (Spark)\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "# For regression and other possible ML tools (Spark)\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.param import Param, Params\n",
        "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.stat import Statistics"
      ],
      "metadata": {
        "id": "OuY0J8h__RLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important for managing features  (Spark)\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# For displaying and other related IPython tools...\n",
        "from IPython.display import display\n",
        "from IPython.html.widgets import interact"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv7iTZV5U5dH",
        "outputId": "b7c3b0f3-398b-436b-f75f-c5779f299a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
            "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col"
      ],
      "metadata": {
        "id": "jm8Ms1VDSV1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Typycal Python tools\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path"
      ],
      "metadata": {
        "id": "PCB1DgsLVq57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Load the data"
      ],
      "metadata": {
        "id": "7oYhpgXBXxiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read.csv('/content/drive/My Drive/Big Data Project/Datasets/data2019-001.csv', header='True')\n",
        "df2 = spark.read.csv('/content/drive/My Drive/Big Data Project/Datasets/data2020.csv', header='True')\n",
        "df3 = spark.read.csv('/content/drive/My Drive/Big Data Project/Datasets/data2021.csv', header='True')"
      ],
      "metadata": {
        "id": "b1sZL5zXXTY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.dtypes"
      ],
      "metadata": {
        "id": "YHPDG8eOlj0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning for Datasets"
      ],
      "metadata": {
        "id": "WhDX54kQf4HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the data shape before starting cleaning\n",
        "\n",
        "print(f\"The shape is {df1.count():d} rows by {len(df1.columns):d} columns.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJc5RXjsPRKP",
        "outputId": "51defd15-156c-4503-c55c-47e0e1e61cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape is 7422037 rows by 110 columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of null values \n",
        "\n",
        "null_counts = df1.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
        "                         for c in df1.columns]).toPandas().to_dict(orient='records')\n",
        "\n",
        "print(f\"We have {sum(null_counts[0].values()):d} null values in this dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA8qLv5rSiRr",
        "outputId": "e4f7e124-878c-474d-b14c-b48ba5c84ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 395605008 null values in this dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.0.0-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = series\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checked whether null values have been dropped\n",
        "\n",
        "null_counts2 = df2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
        "                         for c in df2.columns]).toPandas().to_dict(orient='records')\n",
        "\n",
        "print(f\"We have {sum(null_counts2[0].values()):d} null values in this dataset.\")"
      ],
      "metadata": {
        "id": "WiRjuLrGft4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checked whether null values have been dropped\n",
        "\n",
        "null_counts3 = df3.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
        "                         for c in df3.columns]).toPandas().to_dict(orient='records')\n",
        "\n",
        "print(f\"We have {sum(null_counts3[0].values()):d} null values in this dataset.\")"
      ],
      "metadata": {
        "id": "R7jUby1hhmDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Changing Data types"
      ],
      "metadata": {
        "id": "pjJzd9wMaqAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import (\n",
        "    StringType, BooleanType, IntegerType, FloatType, DateType\n",
        ")"
      ],
      "metadata": {
        "id": "0Ly-wY41bOAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.withColumn(\"YEAR\", df1[\"YEAR\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"MONTH\", df1[\"MONTH\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"DAY_OF_MONTH\", df1[\"DAY_OF_MONTH\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"DAY_OF_WEEK\", df1[\"DAY_OF_WEEK\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"CRS_DEP_TIME\", df1[\"CRS_DEP_TIME\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"CRS_ARR_TIME\", df1[\"CRS_ARR_TIME\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"FLIGHTS\", df1[\"FLIGHTS\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"DISTANCE\", df1[\"DISTANCE\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"DIVERTED\", df1[\"DIVERTED\"].cast(IntegerType()))"
      ],
      "metadata": {
        "id": "SHgXAeBMbVYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Running our classifier and models (FOR 2019 only)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GgHvGmnDkAos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.dtypes"
      ],
      "metadata": {
        "id": "KfJqsifBj45D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of selected columns\n",
        "\n",
        "selected_cols = ['YEAR', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_DEP_TIME', \n",
        "                'CRS_ARR_TIME', 'FLIGHTS', 'DISTANCE', 'DIVERTED']"
      ],
      "metadata": {
        "id": "qRZl4kJ6lzZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and create our new feature vector column\n",
        "\n",
        "df1 = VectorAssembler(inputCols=selected_cols, outputCol=\"features\").transform(df1)"
      ],
      "metadata": {
        "id": "vITfJ5xEkQ3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select input columns\n",
        "\n",
        "df1.select(\"Cancelled\", \"features\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVicMfU3kRn7",
        "outputId": "37d0e9e3-2923-4579-d2f7-341ccb28e23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+\n",
            "|Cancelled|            features|\n",
            "+---------+--------------------+\n",
            "|      0.0|[2019.0,1.0,16.0,...|\n",
            "|      0.0|[2019.0,1.0,17.0,...|\n",
            "|      0.0|[2019.0,1.0,18.0,...|\n",
            "|      0.0|[2019.0,1.0,19.0,...|\n",
            "|      1.0|[2019.0,1.0,20.0,...|\n",
            "+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Constant for the Random Forrest"
      ],
      "metadata": {
        "id": "7Cfrkw25wp7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 141109\n",
        "TRAINING_DATA_RATIO = 0.7\n",
        "RF_NUM_TREES = 8\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "metadata": {
        "id": "LII70gYewv6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the training indexers\n",
        "\n",
        "# Generate a labelIndexer for Cancelled flight\n",
        "labelIndexer = StringIndexer(inputCol=\"CANCELLED\", outputCol=\"indexedLabel\").fit(df1)\n",
        "\n",
        "# Generate the indexed feature vector\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df1)"
      ],
      "metadata": {
        "id": "0T-bXwLdw_Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a labelIndexer for arrival delay\n",
        "labelIndexer1 = StringIndexer(inputCol=\"ARR_DEL15\", outputCol=\"indexedLabel1\").fit(df1)\n",
        "labelIndexer1.setHandleInvalid('skip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cvj5sOx44Fd",
        "outputId": "df859a2b-c7b6-462a-d934-cfa96e9ecd23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringIndexerModel: uid=StringIndexer_e8610144a729, handleInvalid=error"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a labelIndexer for departure delay\n",
        "labelIndexer2 = StringIndexer(inputCol=\"DEP_DEL15\", outputCol=\"indexedLabel2\").fit(df1)\n",
        "labelIndexer2.setHandleInvalid('skip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdv-aXXK5FQw",
        "outputId": "c51e6e73-ca7b-4a72-e5bf-ca189797a927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringIndexerModel: uid=StringIndexer_e65e7e1d8ab5, handleInvalid=error"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Cancelled flight\" as the Estimator\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C_HSyyNczREY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData, testData) = df1.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df1_rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, df1_rf])"
      ],
      "metadata": {
        "id": "iB1w-BPlw1dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "JqQWl4VV1zhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions = model.transform(testData)"
      ],
      "metadata": {
        "id": "hBBsIiTwQ0oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDyRrwa0Q689",
        "outputId": "4167ce9f-ff2a-4b69-9c11-f22819c447aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0181524\n",
            "Accuracy = 0.981848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Arrival Delay\" as the Estimator"
      ],
      "metadata": {
        "id": "-RKKMbdx3eKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData1, testData1) = df1.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df1_rf1 = RandomForestClassifier(labelCol=\"indexedLabel1\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline1 = Pipeline(stages=[labelIndexer1, featureIndexer, df1_rf1])"
      ],
      "metadata": {
        "id": "TbP97YYi4hk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model1 = pipeline1.fit(trainingData1)"
      ],
      "metadata": {
        "id": "N2uC3coc6R6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions1 = model1.transform(testData1)"
      ],
      "metadata": {
        "id": "NuOA_thP6SpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator1 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel1\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator1.evaluate(predictions1)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUvCrHIL6WLi",
        "outputId": "710b9d12-ca26-423d-f8bd-cc7c536634ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.191325\n",
            "Accuracy = 0.808675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Departure Delay\" as the Estimator"
      ],
      "metadata": {
        "id": "zxYWm4HCBa96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData2, testData2) = df1.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df1_rf2 = RandomForestClassifier(labelCol=\"indexedLabel2\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline2 = Pipeline(stages=[labelIndexer2, featureIndexer, df1_rf2])"
      ],
      "metadata": {
        "id": "soOaVW0mBit5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model2 = pipeline2.fit(trainingData2)"
      ],
      "metadata": {
        "id": "ZBer0086CB2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions2 = model2.transform(testData2)"
      ],
      "metadata": {
        "id": "wU4fC2rjCF4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator2 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel2\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator2.evaluate(predictions2)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S50-jDNkCGzy",
        "outputId": "f1f580b7-76c5-4cdb-c29f-692dd54f945f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.187006\n",
            "Accuracy = 0.812994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Running Our Classifier Model (For 2020 only)"
      ],
      "metadata": {
        "id": "zUwcMYM91vIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.dtypes"
      ],
      "metadata": {
        "id": "Dhr469583FgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing specific column datatypes from string to int\n",
        "\n",
        "df2 = df2.withColumn(\"YEAR\", df2[\"YEAR\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"MONTH\", df2[\"MONTH\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"DAY_OF_MONTH\", df2[\"DAY_OF_MONTH\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"DAY_OF_WEEK\", df2[\"DAY_OF_WEEK\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"CRS_DEP_TIME\", df2[\"CRS_DEP_TIME\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"CRS_ARR_TIME\", df2[\"CRS_ARR_TIME\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"FLIGHTS\", df2[\"FLIGHTS\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"DISTANCE\", df2[\"DISTANCE\"].cast(IntegerType()))\n",
        "df2 = df2.withColumn(\"DIVERTED\", df2[\"DIVERTED\"].cast(IntegerType()))"
      ],
      "metadata": {
        "id": "Ifkbf_lf3Lch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of selected columns\n",
        "\n",
        "selected_cols1 = ['YEAR', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_DEP_TIME', \n",
        "                'CRS_ARR_TIME', 'FLIGHTS', 'DISTANCE', 'DIVERTED']"
      ],
      "metadata": {
        "id": "D-v_HTl72f8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and create our new feature vector column\n",
        "\n",
        "df2 = VectorAssembler(inputCols=selected_cols1, outputCol=\"features1\").transform(df2)"
      ],
      "metadata": {
        "id": "zxIZBzRv2zuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select input columns\n",
        "\n",
        "df2.select(\"DEP_DEL15\", \"features1\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX25-ZKz2-mO",
        "outputId": "deeaa38f-f75a-4827-9df5-d7a3f9bcb1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+\n",
            "|DEP_DEL15|           features1|\n",
            "+---------+--------------------+\n",
            "|      1.0|[2020.0,1.0,1.0,3...|\n",
            "|      0.0|[2020.0,1.0,1.0,3...|\n",
            "|      0.0|[2020.0,1.0,1.0,3...|\n",
            "|      0.0|[2020.0,1.0,1.0,3...|\n",
            "|      0.0|[2020.0,1.0,1.0,3...|\n",
            "+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perform and Evaluate the Random Forest Model"
      ],
      "metadata": {
        "id": "_Qn1_LMe6RLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 141109\n",
        "TRAINING_DATA_RATIO = 0.7\n",
        "RF_NUM_TREES = 8\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "metadata": {
        "id": "0xn871Bp7K51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the training indexers\n",
        "\n",
        "# Generate a Departure Indexer\n",
        "DelIndexer = StringIndexer(inputCol=\"DEP_DEL15\", outputCol=\"indexedDel\").fit(df2)\n",
        "DelIndexer.setHandleInvalid('skip')\n",
        "\n",
        "# Generate the indexed feature vector\n",
        "featureIndexer1 = VectorIndexer(inputCol=\"features1\", outputCol=\"indexedFeatures1\", maxCategories=4).fit(df2)"
      ],
      "metadata": {
        "id": "ufgSyP_Ot3Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Arrival Indexer\n",
        "ArrIndexer = StringIndexer(inputCol=\"ARR_DEL15\", outputCol=\"indexedDel1\").fit(df2)\n",
        "ArrIndexer.setHandleInvalid('skip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsmI_z-lt6AJ",
        "outputId": "d5080103-8a70-4658-eae5-740cb4c0148b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringIndexerModel: uid=StringIndexer_2ed5186a08e6, handleInvalid=error"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a CancelIndexer\n",
        "CancelIndexer = StringIndexer(inputCol=\"CANCELLED\", outputCol=\"indexedDel2\").fit(df2)"
      ],
      "metadata": {
        "id": "7zcv_z0OuJjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Departure Delay\" as the Estimator"
      ],
      "metadata": {
        "id": "v_hUKMx7tY0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData3, testData3) = df2.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df2_rf = RandomForestClassifier(labelCol=\"indexedDel\", featuresCol=\"indexedFeatures1\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline3 = Pipeline(stages=[DelIndexer, featureIndexer1, df2_rf])"
      ],
      "metadata": {
        "id": "ZhkpJiwn6s2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model3 = pipeline3.fit(trainingData1)"
      ],
      "metadata": {
        "id": "WRJuzB567HSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions3 = model3.transform(testData3)"
      ],
      "metadata": {
        "id": "-7StJ2fs7XWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator3 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedDel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator3.evaluate(predictions3)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKgaN2nC7l2n",
        "outputId": "d0ec05ae-fe16-4e8e-b1cd-45f7725b4fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0907222\n",
            "Accuracy = 0.909278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Arrival Delay\" as the Estimator"
      ],
      "metadata": {
        "id": "YbopS9HAtkSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData4, testData4) = df2.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df2_rf1 = RandomForestClassifier(labelCol=\"indexedDel1\", featuresCol=\"indexedFeatures1\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline4 = Pipeline(stages=[ArrIndexer, featureIndexer1, df2_rf1])"
      ],
      "metadata": {
        "id": "ViUWDl5Xtxdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model4 = pipeline4.fit(trainingData4)"
      ],
      "metadata": {
        "id": "I_BBTkyJ2lbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions4 = model4.transform(testData4)"
      ],
      "metadata": {
        "id": "uxxuEp6o6suG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator4 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedDel1\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator4.evaluate(predictions4)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gduxfTId6wAa",
        "outputId": "aba32273-8244-4fa5-8eb1-ded8404163a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0980773\n",
            "Accuracy = 0.901923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Cancelled\" as the Estimator"
      ],
      "metadata": {
        "id": "IhDV5GHt2ANZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData5, testData5) = df2.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df2_rf2 = RandomForestClassifier(labelCol=\"indexedDel2\", featuresCol=\"indexedFeatures1\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline5 = Pipeline(stages=[CancelIndexer, featureIndexer1, df2_rf2])"
      ],
      "metadata": {
        "id": "0O2FJ5ih9EhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model5 = pipeline5.fit(trainingData5)"
      ],
      "metadata": {
        "id": "uUE2EKDr9GfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions5 = model5.transform(testData5)"
      ],
      "metadata": {
        "id": "bNzt1s0l9Lq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator5 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedDel2\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator5.evaluate(predictions5)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Tk-xMJ-1Q_",
        "outputId": "b7573a29-cf06-4670-946f-ceccb3d88825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0601021\n",
            "Accuracy = 0.939898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Running Our Classifier Model (For 2021 only)"
      ],
      "metadata": {
        "id": "gBMo4fpbyoq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing specific column datatypes from string to int\n",
        "\n",
        "df3 = df3.withColumn(\"YEAR\", df3[\"YEAR\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"MONTH\", df3[\"MONTH\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"DAY_OF_MONTH\", df3[\"DAY_OF_MONTH\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"DAY_OF_WEEK\", df3[\"DAY_OF_WEEK\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"CRS_DEP_TIME\", df3[\"CRS_DEP_TIME\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"CRS_ARR_TIME\", df3[\"CRS_ARR_TIME\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"FLIGHTS\", df3[\"FLIGHTS\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"DISTANCE\", df3[\"DISTANCE\"].cast(IntegerType()))\n",
        "df3 = df3.withColumn(\"DIVERTED\", df3[\"DIVERTED\"].cast(IntegerType()))"
      ],
      "metadata": {
        "id": "1iyFMrU2yrlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of selected columns\n",
        "\n",
        "selected_cols2 = ['YEAR', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_DEP_TIME', \n",
        "                'CRS_ARR_TIME', 'FLIGHTS', 'DISTANCE', 'DIVERTED']"
      ],
      "metadata": {
        "id": "YV-jCrpsy0AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and create our new feature vector column\n",
        "\n",
        "df3 = VectorAssembler(inputCols=selected_cols2, outputCol=\"features2\").transform(df3)"
      ],
      "metadata": {
        "id": "BMBov-1Ly2jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select input columns\n",
        "\n",
        "df3.select(\"ARR_DEL15\", \"features2\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9Hhi81m0Y7W",
        "outputId": "c9295b52-63aa-428b-8472-50a4c4e77f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+\n",
            "|ARR_DEL15|           features2|\n",
            "+---------+--------------------+\n",
            "|      0.0|[2021.0,1.0,5.0,2...|\n",
            "|      0.0|[2021.0,1.0,5.0,2...|\n",
            "|      0.0|[2021.0,1.0,5.0,2...|\n",
            "|      0.0|[2021.0,1.0,5.0,2...|\n",
            "|      0.0|[2021.0,1.0,5.0,2...|\n",
            "+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perform and Evaluate the Random Forest Model"
      ],
      "metadata": {
        "id": "QwlNQA1Y2FVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the training indexers\n",
        "\n",
        "# Generate a Arrival Indexer\n",
        "ArrIndexer1 = StringIndexer(inputCol=\"ARR_DEL15\", outputCol=\"indexedArr\").fit(df3)\n",
        "ArrIndexer1.setHandleInvalid('skip')\n",
        "\n",
        "# Generate the indexed feature vector\n",
        "featureIndexer2 = VectorIndexer(inputCol=\"features2\", outputCol=\"indexedFeatures2\", maxCategories=4).fit(df3)"
      ],
      "metadata": {
        "id": "CdspxT_t0w9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Departure Indexer\n",
        "DelIndexer1 = StringIndexer(inputCol=\"DEP_DEL15\", outputCol=\"indexedArr1\").fit(df3)\n",
        "DelIndexer1.setHandleInvalid('skip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3bqOLiLDHTS",
        "outputId": "2ca63ff5-34e3-4644-fec3-91652f222a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringIndexerModel: uid=StringIndexer_72f30991854f, handleInvalid=error"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Cancelled Indexer\n",
        "CancelIndexer1 = StringIndexer(inputCol=\"CANCELLED\", outputCol=\"indexedArr2\").fit(df3)\n",
        "CancelIndexer1.setHandleInvalid('skip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUHwmrfCDOPl",
        "outputId": "2fb1513c-a100-4be1-c2d2-c11d256e8e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringIndexerModel: uid=StringIndexer_d43c80d3c11a, handleInvalid=error"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Arrival Delay\" as the Estimator"
      ],
      "metadata": {
        "id": "1jotn3s-B_63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData6, testData6) = df3.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df3_rf = RandomForestClassifier(labelCol=\"indexedArr\", featuresCol=\"indexedFeatures2\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline6 = Pipeline(stages=[ArrIndexer1, featureIndexer2, df3_rf])"
      ],
      "metadata": {
        "id": "6LqWB69O2plm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model6 = pipeline6.fit(trainingData6)"
      ],
      "metadata": {
        "id": "yorbzMJI25oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions6 = model6.transform(testData6)"
      ],
      "metadata": {
        "id": "JBcj3X1i3ABI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator6 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedArr\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator6.evaluate(predictions6)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qwNK7Bd3IRH",
        "outputId": "171d4449-24c6-42e3-b2a2-d1f1c6f6ceea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.17194\n",
            "Accuracy = 0.82806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Departure Delay\" as the Estimator"
      ],
      "metadata": {
        "id": "Zbxx_52lF5Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData7, testData7) = df3.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df3_rf1 = RandomForestClassifier(labelCol=\"indexedArr1\", featuresCol=\"indexedFeatures2\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline7 = Pipeline(stages=[DelIndexer1, featureIndexer2, df3_rf1])"
      ],
      "metadata": {
        "id": "g_97ZjvvGu8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model7 = pipeline7.fit(trainingData7)"
      ],
      "metadata": {
        "id": "wZbxROgGIoSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions7 = model7.transform(testData7)"
      ],
      "metadata": {
        "id": "SFO_8KguIu_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator7 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedArr1\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator7.evaluate(predictions7)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIkIyvBZIyBH",
        "outputId": "80ca7eb1-da5a-413d-e6c5-2a2f1469b354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.173875\n",
            "Accuracy = 0.826125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluating the model with \"Cancelled\" as the Estimator"
      ],
      "metadata": {
        "id": "b3V9957uF9yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and tests sets\n",
        "(trainingData8, testData8) = df3.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "df3_rf1 = RandomForestClassifier(labelCol=\"indexedArr2\", featuresCol=\"indexedFeatures2\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline8 = Pipeline(stages=[CancelIndexer1, featureIndexer2, df3_rf1])"
      ],
      "metadata": {
        "id": "ACi4W-knGuQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "model8 = pipeline8.fit(trainingData8)"
      ],
      "metadata": {
        "id": "uzbgWkklKKLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "predictions8 = model8.transform(testData8)"
      ],
      "metadata": {
        "id": "IXvVdmTkKS1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select prediction, true label and compute test error\n",
        "evaluator8 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedArr2\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator8.evaluate(predictions8)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbJ46qh6KXJc",
        "outputId": "ee42af90-af6f-4250-a642-fab712baf274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0172961\n",
            "Accuracy = 0.982704\n"
          ]
        }
      ]
    }
  ]
}